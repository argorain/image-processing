{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Classification to ImageNet Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.data import get_image_from_url\n",
    "from utils.data import init_model_logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.contrib import slim\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - http://www.image-net.org/search?q=dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_ckpt = '/data/checkpoints/resnet_v1_50.ckpt'\n",
    "renset_class_names = '/data/checkpoints/resnet_v1_50_catnames.pickle'\n",
    "\n",
    "with open(renset_class_names, 'rb') as fr:\n",
    "    imagenet_category_names = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagenet_category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Resnet Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - https://github.com/tensorflow/models/tree/master/research/slim \n",
    " - https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v1.py   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.variable_scope('resnet_inputs'):\n",
    "        images = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "     \n",
    "    # Syntactic sugar which encapsulates more resnet parameters\n",
    "    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "        raw_prediction, othere_layers = resnet_v1.resnet_v1_50(\n",
    "            images, output_stride=None, num_classes=1000, global_pool=True, \n",
    "            is_training=is_training, scope='resnet_v1_50')\n",
    "        \n",
    "    with tf.name_scope('softmax_prediction'):\n",
    "        prediction = tf.nn.softmax(tf.reshape(raw_prediction, shape=(-1, 1000)))\n",
    "    \n",
    "    # Operation which will load trained parameters to resnet part of network\n",
    "    init_resnet = slim.assign_from_checkpoint_fn(resnet_model_ckpt, slim.get_model_variables('resnet_v1_50'))\n",
    "    initialize_vars = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/tensorboard_summaries/resnet/'\n",
    "logging_meta = init_model_logging(base_dir, 'experiment_1', graph=graph, remove_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://british-samoyed-club.co.uk/bsc/wp-content/uploads/scooter.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image and reshape to batch format.\n",
    "image_shape = [224, 224, 3]\n",
    "samoyed_img = get_image_from_url(url, image_shape)\n",
    "samoyed_img = samoyed_img.reshape([-1, 224, 224, 3])\n",
    "\n",
    "# Plot image.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(samoyed_img[0].astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "        \n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    init_resnet(session)\n",
    "    _prediction, = session.run([prediction], feed_dict={is_training: False, images: samoyed_img})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_softmax = _prediction[0]\n",
    "top_n = 10\n",
    "top_label_class_ids = np.argsort(output_softmax)[-1:0:-1][:top_n]\n",
    "top_label_class_scores = output_softmax[top_label_class_ids]\n",
    "\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "rects = ax.bar(np.arange(top_n), top_label_class_scores, 0.5, color='r')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "results = plt.xticks(np.arange(top_n), [imagenet_category_names[cat_id] for cat_id in top_label_class_ids], rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt Image with Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pbs.twimg.com/media/DSU7iNMU8AAciHy.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload patches.\n",
    "image_shape = [224, 224, 3]\n",
    "patches_img = get_image_from_url(url, image_shape)\n",
    "patches_img = patches_img.reshape([-1, 224, 224, 3])\n",
    "\n",
    "# Plot patches.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(patches_img[0].astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick patch\n",
    "row_id in [0, 1]\n",
    "\n",
    "col_id in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of patches.\n",
    "row_id = 1\n",
    "col_id = 0\n",
    "toaster_patch_img = patches_img[0][row_id*112:(row_id+1)*112, col_id*112:(col_id+1)*112, :]\n",
    "\n",
    "# Plot patch.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(toaster_patch_img.astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupt image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge patch with original image.\n",
    "toaster_pixel_ids = np.where(toaster_patch_img > 0)\n",
    "\n",
    "corruptd_samoyed_img = samoyed_img.copy()\n",
    "corruptd_samoyed_img[0][toaster_pixel_ids] = toaster_patch_img[toaster_pixel_ids]\n",
    "\n",
    "# Plot Merge.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(corruptd_samoyed_img[0].astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Net on Corrupted Image and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run net on corrupted image.\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "        \n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run([initialize_vars])\n",
    "    init_resnet(session)\n",
    "    _prediction, = session.run([prediction], feed_dict={is_training: False, images: corruptd_samoyed_img})\n",
    "    \n",
    "# Plot results.\n",
    "output_softmax = _prediction[0]\n",
    "top_n = 10\n",
    "top_label_class_ids = np.argsort(output_softmax)[-1:0:-1][:top_n]\n",
    "top_label_class_scores = output_softmax[top_label_class_ids]\n",
    "\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "rects = ax.bar(np.arange(top_n), top_label_class_scores, 0.5, color='r')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "results = plt.xticks(np.arange(top_n), [imagenet_category_names[cat_id] for cat_id in top_label_class_ids], rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Strange Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Strange Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.evolvingai.org/files/70_images_entry_v2_web.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load strange images with appropriate size.\n",
    "image_shape = [7 * 330, 10 * 224, 3]\n",
    "strange_imgs = get_image_from_url(url, image_shape)\n",
    "strange_imgs = strange_imgs.reshape([-1, 7 * 330, 10 * 224, 3])\n",
    "\n",
    "# Plot images.\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(strange_imgs[0].astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick One Strange Image\n",
    "row_id in [0, 6]\n",
    "\n",
    "col_id in [0, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = 4\n",
    "col_id = 6\n",
    "strange_img = strange_imgs[:, row_id*330: row_id*330 + 224, col_id*224:(col_id+1)*224,:]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(strange_img[0].astype(np.uint8))\n",
    "ax = plt.gca()\n",
    "ax.axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Net and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run net on strange image.\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "        \n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    init_resnet(session)\n",
    "    _prediction, = session.run([prediction], feed_dict={is_training: False, images: strange_img})\n",
    "\n",
    "# Plot results.  \n",
    "output_softmax = _prediction[0]\n",
    "top_n = 10\n",
    "top_label_class_ids = np.argsort(output_softmax)[-1:0:-1][:top_n]\n",
    "top_label_class_scores = output_softmax[top_label_class_ids]\n",
    "\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "rects = ax.bar(np.arange(top_n), top_label_class_scores, 0.5, color='r')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "results = plt.xticks(np.arange(top_n), [imagenet_category_names[cat_id] for cat_id in top_label_class_ids], rotation='vertical')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
