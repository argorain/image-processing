{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Convolution Layer on Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as ipw\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interactive\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from utils.nn_visualization import conv_filter_widget\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_data.read_data_sets('/data/fashion/')\n",
    "class_id2class_name_mapping = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose on of images from batch\n",
    "image_id = 1\n",
    "batch_size = 10\n",
    "images = data.validation.images[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert image_id < batch_size\n",
    "image = images[image_id].reshape(28,28)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "im = plt.imshow(image, cmap='gray')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "plt.gca().axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter = np.array(\n",
    "    [[-1, -1, -1, 1], \n",
    "     [-1, -1,  1, 1], \n",
    "     [-1,  1,  1, 1],\n",
    "     [ 1,  1,  1, 1]], dtype=np.float32)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "im = plt.imshow(conv_filter, cmap='gray')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "ax = plt.gca()\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_row = 1\n",
    "stride_col = 1\n",
    "padding = \"SAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and Filter shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Convolution Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reshaped = image.reshape((1, 28, 28, 1))\n",
    "conv_filter_reshaped = conv_filter.reshape(conv_filter.shape[0], conv_filter.shape[1], 1, 1)\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_image = tf.constant(image_reshaped)\n",
    "    tf_conv_filer = tf.constant(conv_filter_reshaped)\n",
    "    tf_conv_layer = tf.nn.conv2d(tf_image, tf_conv_filer, strides=[1, stride_row, stride_col, 1], padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    conv_layer = sess.run(tf_conv_layer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe Convolution Layer Output Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if padding == 'VALID':\n",
    "    conv_layer_shape = (np.floor((28 - conv_filter.shape[0] + stride_row) / stride_row).astype(int), \n",
    "                        np.floor((28. - conv_filter.shape[1] + stride_col) / stride_col).astype(int))\n",
    "elif padding == 'SAME':\n",
    "    conv_layer_shape = (np.ceil(28 / stride_row).astype(int), \n",
    "                        np.ceil(28 /stride_col).astype(int))\n",
    "\n",
    "conv_layer = conv_layer.reshape(conv_layer_shape)\n",
    "conv_layer_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input vs. Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "ax = plt.subplot(gs[0, 1])\n",
    "plt.title(\"Convolved\")\n",
    "im = plt.imshow(conv_layer, cmap='gray')\n",
    "plt.gca().axes.set_axis_off()\n",
    "\n",
    "ax = plt.subplot(gs[0, 0])\n",
    "plt.title('Input')\n",
    "im = plt.imshow(image, cmap='gray')\n",
    "plt.gca().axes.set_axis_off()\n",
    "\n",
    "\n",
    "ax = plt.subplot(gs[1, :2])\n",
    "plt.title('filter')\n",
    "im = plt.imshow(conv_filter, cmap='gray')\n",
    "plt.colorbar(im, orientation='horizontal')\n",
    "\n",
    "plt.gca().axes.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity of Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_max = conv_layer.max()\n",
    "def plot_conv_layer(tolerance):\n",
    "    conv_layer_filtered = (conv_layer >= (conv_layer_max - tolerance)).astype(int)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    im = plt.imshow(conv_layer_filtered, cmap='gray')\n",
    "    plt.colorbar(im, orientation='horizontal')\n",
    "    plt.gca().axes.set_axis_off()\n",
    "    plt.show()\n",
    "    \n",
    "interactive(plot_conv_layer, \n",
    "            tolerance=ipw.FloatSlider(0.5, min=0, max=conv_layer_max - 0.1, step=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Convolution Filter\n",
    " - top\n",
    " - left\n",
    " - bottom\n",
    " - right\n",
    " - diag_left\n",
    " - diag_righ\n",
    " - top_half\n",
    " - bottom_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter_widget(image, conv_filter_shape=[4, 4], stride_col=2, stride_row=2, init_mode='right', padding='SAME')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
