{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Finetuning on MSCOCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.nn_graph import simple_layer, variable_summaries\n",
    "from utils.data import init_model_logging\n",
    "from utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data:\n",
    "    train = Dataset('/data/mscoco/train_data.hdf', '/data/mscoco/train_imgs/', one_hot=True, norm=False)\n",
    "    validation = Dataset('/data/mscoco/valid_data.hdf', '/data/mscoco/valid_imgs/', one_hot=True, norm=False)\n",
    "    \n",
    "class_id2class_name_mapping = {\n",
    "    0: 'cow',\n",
    "    1: 'sheep',\n",
    "    2: 'giraffe',\n",
    "    3: 'horse',\n",
    "    4: 'bird',\n",
    "    5: 'cat',\n",
    "    6: 'dog',\n",
    "    7: 'elephant',\n",
    "    8: 'bear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Resnet Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_ckpt = '/data/checkpoints/resnet_v1_50.ckpt'\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.variable_scope('resnet_inputs'):\n",
    "        images = tf.placeholder(dtype=tf.float32, shape=[None, 224 * 224 * 3], name='images')\n",
    "        labels = tf.placeholder(tf.float32, shape=(None, 9), name='labels')\n",
    "        is_training = tf.placeholder(tf.bool, shape=(), name='training_flag')\n",
    "\n",
    "    with tf.name_scope('image_reshape'):        \n",
    "        images_reshaped = tf.reshape(images, [-1, 224, 224, 3])        \n",
    "\n",
    "    #########################\n",
    "    # Resnet part of model. #\n",
    "    #########################\n",
    "        \n",
    "    # Run resnet in mode, where it returns embedding insted of prediction itself.\n",
    "    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "        resnet_tensors = resnet_v1.resnet_v1_50(\n",
    "            images_reshaped, is_training=is_training, num_classes=None,\n",
    "            global_pool=True, scope='resnet_v1_50')\n",
    "        \n",
    "    # Here we get embedding vector from pretrained model. \n",
    "    # This is point where to join our custom network.\n",
    "    resnet_feature_vector, resnet_endpoints = resnet_tensors\n",
    "\n",
    "    with tf.name_scope('resnet_feature_vector'):\n",
    "        resnet_feature_vector = tf.reshape(resnet_feature_vector, shape=(-1, 2048))\n",
    "\n",
    "    ########################\n",
    "    # Our Custom Netowork. #\n",
    "    ########################\n",
    "        \n",
    "    with tf.variable_scope('layer1'):\n",
    "        prediction_raw = resnet_feature_vector\n",
    "        prediction_raw = simple_layer('layer1', prediction_raw, shape=[2048, 1024], activation='relu')\n",
    "        \n",
    "    with tf.variable_scope('layer2'):\n",
    "        prediction_raw = simple_layer('layer2', prediction_raw, shape=[1024, 9], activation='linear')\n",
    "\n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.nn.softmax(prediction_raw)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy_vector = tf.losses.softmax_cross_entropy(logits=prediction_raw, onehot_labels=labels)\n",
    "        variable_summaries('loss_summary', cross_entropy_vector)\n",
    "        loss = tf.reduce_mean(cross_entropy_vector)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        variable_summaries('accuracy_summary', correct_prediction)     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    # Transfer learning setup with 2 optimizers istead of 1 #\n",
    "    #########################################################\n",
    "    with tf.name_scope('training'):\n",
    "        loss_to_optimize = loss\n",
    "        \n",
    "        ##################################################################################\n",
    "        # Selecting trainable variables from upper part of resnet and our custom network #\n",
    "        ##################################################################################\n",
    "        \n",
    "        # Select all trainable variables (weights) from our net and resnet\n",
    "        var_all = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        print(\"All trainable variables from  model (printed first 5).\")\n",
    "        print(var_all[:5], '\\n')\n",
    "        \n",
    "        # Select trainable variables only from resnet model.\n",
    "        var_resnet = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='resnet_v1_50')\n",
    "        # Select all trainable variables from resnet 2 most upper blocks, checkout tensorboard graph\n",
    "        var_resnet_3_and_4 = list(filter(lambda var: 'block3' in var.name or 'block4' in var.name, var_resnet))\n",
    "        print(\"Trainable varibles from block3 and block4 of resnet (printed fist 5).\")\n",
    "        print(var_resnet_3_and_4[:5], '\\n')\n",
    "        \n",
    "        # Select trainable variables from our custom network joined to resnet\n",
    "        var_top = list(set(var_all) - set(var_resnet))\n",
    "        print(\"Trainable varibles from our custom network (printed fist 5).\")\n",
    "        print(var_top[:5], '\\n')\n",
    "        \n",
    "        #####################################################\n",
    "        # Count gradients of loss based on chosen variables #\n",
    "        #####################################################\n",
    "        \n",
    "        # Define gradinets with respect to loss for all variables.\n",
    "        gradients = tf.gradients(loss_to_optimize, var_resnet_3_and_4 + var_top)\n",
    "        # Select gradients for block3 and block4 of resnet.\n",
    "        gradients_resnet = gradients[:len(var_resnet_3_and_4)]\n",
    "        # Select gradient for our custom network\n",
    "        gradients_top = gradients[len(var_resnet_3_and_4):]\n",
    "\n",
    "        ###################################################\n",
    "        # 2 optimizers with different learning rate setup #\n",
    "        ###################################################\n",
    "        \n",
    "        # This optimizer will apply gradients to resnet block3 and block4.\n",
    "        # Using very small step which won't change weights much.\n",
    "        optimizer_resnet = tf.train.AdamOptimizer(0.0001)\n",
    "        # This optimizer will train custom net.\n",
    "        # Using normal learning rate.\n",
    "        optimizer_top = tf.train.AdamOptimizer(0.001)\n",
    "\n",
    "        # Substitute minimize method with gradients and apply_gradients methods.\n",
    "        train_resnet = optimizer_resnet.apply_gradients(zip(gradients_resnet, var_resnet_3_and_4))\n",
    "        train_top = optimizer_top.apply_gradients(zip(gradients_top, var_top))\n",
    "        \n",
    "        # Dependencies because of batch normalization.\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_step = tf.group(train_resnet, train_top)\n",
    "            # This wouldn't work since it's to high step for already trained part of resent \n",
    "            # train_step = tf.train.AdamOptimizer(0.001).minimize(loss_to_optimize)\n",
    "            \n",
    "    init_resnet = slim.assign_from_checkpoint_fn(resnet_model_ckpt, slim.get_model_variables('resnet_v1_50'))\n",
    "    initialize_vars = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "    merge_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/tensorboard_summaries/resnet/'\n",
    "exp_name = 'experiment_finetune_two_optimizers'\n",
    "\n",
    "logging_meta = init_model_logging(base_dir, exp_name, graph=graph, remove_existing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model_path = logging_meta['model_path']\n",
    "\n",
    "validation_feed_dict = {\n",
    "    images: data.validation.images, \n",
    "    labels: data.validation.labels,\n",
    "    is_training: False}\n",
    "\n",
    "with tf.Session(graph=graph, config=config) as session:\n",
    "    session.run(initialize_vars)\n",
    "    init_resnet(session)\n",
    "    for iteration in range(1901):\n",
    "        ##################\n",
    "        # Training Phase #\n",
    "        ##################\n",
    "        \n",
    "        _images, _labels = data.train.next_batch(30)\n",
    "        feed_dict={images: _images, labels: _labels, is_training: True}\n",
    "        _ = session.run([train_step], feed_dict)\n",
    " \n",
    "\n",
    "        #################\n",
    "        # Logging Phase #\n",
    "        #################\n",
    "\n",
    "        # Train log\n",
    "        feed_dict={images: _images, labels: _labels, is_training: False}\n",
    "        _summary,  _accuracy, _loss = session.run([merge_summaries, accuracy, loss], feed_dict)\n",
    "        print(\"Iteration Train {}: loss {}, accuracy {}\".format(iteration, _loss, _accuracy))\n",
    "        logging_meta['train_writer'].add_summary(_summary, iteration)\n",
    "        \n",
    "        # Valid log\n",
    "        if iteration % 100 == 0:\n",
    "            _summary, _accuracy, _loss = session.run([merge_summaries, accuracy, loss], validation_feed_dict)\n",
    "            logging_meta['valid_writer'].add_summary(_summary, iteration)\n",
    "            logging_meta['saver'].save(session, model_path, iteration)\n",
    "            print(\"= Valid Iteration {}: loss {}, accuracy {} =\".format(iteration, _loss, _accuracy))\n",
    "    \n",
    "    _prediction, = session.run([prediction], validation_feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.results_evaluation import get_accuracy\n",
    "from utils.results_evaluation import get_false_positives\n",
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_rec_prec\n",
    "from utils.results_evaluation import plot_coocurance_matrix\n",
    "from utils.results_evaluation import plot_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_info_df(data.validation.labels, _prediction, class_id2class_name_mapping, data.validation.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df, use_top3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_prec(df, class_id2class_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurance_matrix(df, use_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_false_positives(df, 'horse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(fp, [224, 224 , 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
