{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Image Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.nn_visualization import variable_summaries\n",
    "from utils.data import init_model_logging\n",
    "from utils.nn_graph import simple_layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = image.reshape(1, 28, 28)\n",
    "        return {'image': image, \n",
    "                'label': label}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)} \n",
    "    \n",
    "transform = Compose([Reshape(), ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id2class_name_mapping = {\n",
    "            0: 'T-shirt/top',\n",
    "            1: 'Trouser',\n",
    "            2: 'Pullover',\n",
    "            3: 'Dress',\n",
    "            4: 'Coat',\n",
    "            5: 'Sandal',\n",
    "            6: 'Shirt',\n",
    "            7: 'Sneaker',\n",
    "            8: 'Bag',\n",
    "            9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistDataset(Dataset):\n",
    "    def __init__(self, raw_data, transform=None):\n",
    "        self.raw_data = raw_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.raw_data.num_examples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {'image': self.raw_data.images[idx], \n",
    "                'label': self.raw_data.labels[idx]}\n",
    "        if self.transform is not None:\n",
    "            return transform(item)\n",
    "        else:\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fashion_mnist_dataset = input_data.read_data_sets('/data/fashion/', one_hot=True, reshape=False)\n",
    "train_data = FashionMnistDataset(raw_fashion_mnist_dataset.train, transform=transform)\n",
    "valid_data = FashionMnistDataset(raw_fashion_mnist_dataset.validation, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batcher = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_data_batcher = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(train_data_batcher).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic conv and feed forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "       \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        return x\n",
    "    \n",
    "class FFNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNet, self).__init__()\n",
    "        \n",
    "        self.w = torch.empty(64 * 5 * 5, 10, device=device, dtype=dtype, requires_grad=True)\n",
    "        self.w = torch.nn.init.xavier_normal_(self.w)\n",
    "        self.w = torch.nn.Parameter(self.w)\n",
    "        \n",
    "        self.b = torch.zeros(10, device=device, dtype=dtype, requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(self.b)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 64 * 5 * 5))\n",
    "        return x.mm(self.w) + self.b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = ConvNet()\n",
    "ff_net = FFNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(conv_net.parameters()) + list(ff_net.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_id in range(25):\n",
    "    for iteration, batch in enumerate(train_data_batcher, 1):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        labels = torch.max(labels, 1)[1]\n",
    "        \n",
    "        conv_layer = conv_net(images)\n",
    "        outputs = ff_net(conv_layer)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 30 == 0:\n",
    "            correct_match = []\n",
    "            with torch.no_grad():\n",
    "                for valid_batch in valid_data_batcher:\n",
    "                    images, labels = valid_batch['image'], valid_batch['label']\n",
    "                    labels = torch.max(labels, 1)[1]\n",
    "\n",
    "                    conv_layer = conv_net(images)\n",
    "                    outputs = ff_net(conv_layer)\n",
    "                    correct_match += (torch.max(outputs, 1)[1] == labels).squeeze().numpy().tolist()\n",
    "                \n",
    "                print(\"accuracy \", np.mean(np.array(correct_match)))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for valid_batch in valid_data_batcher:\n",
    "        images, labels = valid_batch['image'], valid_batch['label']\n",
    "        labels = torch.max(labels, 1)[1]\n",
    "\n",
    "        conv_layer = conv_net(images)\n",
    "        outputs = ff_net(conv_layer)\n",
    "        \n",
    "        correct_match = (torch.max(outputs, 1)[1] == labels).squeeze()\n",
    "        for idx in range(correct_match.shape[0]):\n",
    "            label = labels[idx]\n",
    "            class_correct[label] += correct_match[idx].item()\n",
    "            class_total[label] += 1\n",
    "    for i in range(10):\n",
    "        print('Accuracy of class {0} : {1:.2f}'.format(class_id2class_name_mapping[i], 100 * class_correct[i] / class_total[i]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_accuracy\n",
    "from utils.results_evaluation import get_false_positives\n",
    "from utils.results_evaluation import get_info_df\n",
    "from utils.results_evaluation import get_rec_prec\n",
    "from utils.results_evaluation import plot_coocurance_matrix\n",
    "from utils.results_evaluation import plot_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images  = torch.from_numpy(valid_data.raw_data.images.reshape(-1, 1, 28, 28))\n",
    "conv_layer = conv_net(validation_images)\n",
    "outputs = ff_net(conv_layer)\n",
    "\n",
    "_prediction = torch.nn.functional.softmax(outputs, dim=1)\n",
    "_prediction = _prediction.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_info_df(valid_data.raw_data.labels, _prediction, class_id2class_name_mapping, valid_data.raw_data.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_prec(df, class_id2class_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_false_positives(df, 'Shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurance_matrix(df, use_top3=False, use_log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
